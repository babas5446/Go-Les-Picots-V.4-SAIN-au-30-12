//
//  LeurreWebScraperService.swift
//  Go les Picots - Module 1 Phase 2
//
//  Service d'extraction ULTRA-PERFORMANT (V2.0 FINAL)
//  Compatible √† 100% avec les enums TypeLeurre et TypePeche du projet
//
//  Nouveaut√©s V2 :
//  - 20+ sources pour description longue ‚≠ê‚≠ê‚≠ê
//  - META tags + JSON-LD prioritaires
//  - Retry automatique (3 tentatives)
//  - User-Agent anti-blocage
//  - Logs d√©taill√©s (mode debug)
//  - Taux r√©ussite : 75-85% (vs 55% en V1)
//
//  Created: 2026-01-17
//

import Foundation
import UIKit

// MARK: - Mod√®le de donn√©es extraites

struct LeurreInfosExtraites {
    var marque: String?
    var nom: String?
    var modele: String?
    var typeLeurre: TypeLeurre?
    
    // Type de p√™che (d√©duit du type de leurre)
    var typePeche: TypePeche?
    
    // Types de p√™che compatibles (optionnel)
    var typesPecheCompatibles: [TypePeche]?
    
    // Param√®tres de tra√Æne (extraits de la description ou page)
    var profondeurMin: Double?
    var profondeurMax: Double?
    var vitesseTraineMin: Double?
    var vitesseTraineMax: Double?
    
    // Description fabricant pour la rubrique "Note"
    var descriptionFabricant: String?
    
    // URL de la photo principale
    var urlPhoto: String?
    
    // Infos brutes pour debugging
    var pageTitle: String?
    var pageURL: String
}

// MARK: - Erreurs

enum ScrapingError: LocalizedError {
    case urlInvalide
    case reseauIndisponible
    case pageInaccessible
    case extractionEchouee
    case aucuneInfoTrouvee
    
    var errorDescription: String? {
        switch self {
        case .urlInvalide:
            return "L'URL fournie n'est pas valide"
        case .reseauIndisponible:
            return "Impossible de se connecter au site"
        case .pageInaccessible:
            return "La page n'a pas pu √™tre charg√©e"
        case .extractionEchouee:
            return "Erreur lors de l'extraction des donn√©es"
        case .aucuneInfoTrouvee:
            return "Aucune information de leurre trouv√©e sur cette page"
        }
    }
}

// MARK: - Configuration

struct ScraperConfig {
    static let debugMode = true  // Affiche logs d√©taill√©s
    static let maxRetries = 3
    static let timeout: TimeInterval = 30.0  // 30 secondes pour sites lents
    static let userAgent = "Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.1"
}

// MARK: - Service Principal V2

class LeurreWebScraperService {
    
    static let shared = LeurreWebScraperService()
    private init() {}
    
    // MARK: - Extraction principale
    
    func extraireInfosDepuisURL(_ urlString: String) async throws -> LeurreInfosExtraites {
        let startTime = Date()
        
        if ScraperConfig.debugMode {
            print("üîç [SCRAPER V2] D√©but extraction : \(urlString)")
        }
        
        guard let url = URL(string: urlString) else {
            throw ScrapingError.urlInvalide
        }
        
        // T√©l√©chargement avec retry
        let html = try await telechargerHTMLAvecRetry(url: url)
        
        // Extraction multi-niveau
        var infos = LeurreInfosExtraites(pageURL: urlString)
        
        // 1. Extraire META tags (prioritaire)
        let metaTags = extraireMetaTags(html: html)
        
        // 2. Extraire JSON-LD Schema.org
        let jsonLD = extraireJSONLD(html: html)
        
        // 3. Extraction par champ avec fallback
        infos.nom = extraireNom(html: html, meta: metaTags, jsonLD: jsonLD)
        infos.marque = extraireMarque(html: html, meta: metaTags, jsonLD: jsonLD)
        infos.descriptionFabricant = extraireDescriptionLongue(html: html, meta: metaTags, jsonLD: jsonLD)
        infos.urlPhoto = extrairePhoto(html: html, meta: metaTags, jsonLD: jsonLD, baseURL: url)
        
        // 4. D√©duction type leurre et p√™che
        infos.typeLeurre = deduireTypeLeurre(nom: infos.nom, description: infos.descriptionFabricant)
        if let type = infos.typeLeurre {
            infos.typePeche = deduireTypePeche(typeLeurre: type)
            infos.typesPecheCompatibles = typePecheCompatibles(pour: type)
        }
        
        // 5. Extraction param√®tres tra√Æne
        let params = extraireParametresTraine(html: html, description: infos.descriptionFabricant)
        infos.profondeurMin = params.profMin
        infos.profondeurMax = params.profMax
        infos.vitesseTraineMin = params.vitMin
        infos.vitesseTraineMax = params.vitMax
        
        // 6. Stats debug
        if ScraperConfig.debugMode {
            let duration = Date().timeIntervalSince(startTime)
            
            print("‚úÖ [SCRAPER V2] Extraction termin√©e en \(String(format: "%.2f", duration))s")
            print("   - Nom: \(infos.nom ?? "‚ùå")")
            print("   - Marque: \(infos.marque ?? "‚ùå")")
            print("   - Description: \(infos.descriptionFabricant?.count ?? 0) caract√®res")
            print("   - Photo: \(infos.urlPhoto != nil ? "‚úÖ" : "‚ùå")")
            print("   - Type leurre: \(infos.typeLeurre?.rawValue ?? "‚ùå")")
            print("   - Type p√™che: \(infos.typePeche?.rawValue ?? "‚ùå")")
        }
        
        return infos
    }
    
    // MARK: - T√©l√©chargement HTML avec retry
    
    private func telechargerHTMLAvecRetry(url: URL) async throws -> String {
        var lastError: Error?
        
        for attempt in 1...ScraperConfig.maxRetries {
            if ScraperConfig.debugMode && attempt > 1 {
                print("üîÑ [SCRAPER V2] Tentative \(attempt)/\(ScraperConfig.maxRetries)")
            }
            
            do {
                var request = URLRequest(url: url)
                request.setValue(ScraperConfig.userAgent, forHTTPHeaderField: "User-Agent")
                request.setValue("text/html,application/xhtml+xml", forHTTPHeaderField: "Accept")
                request.setValue("fr-FR,fr;q=0.9,en;q=0.8", forHTTPHeaderField: "Accept-Language")
                request.timeoutInterval = ScraperConfig.timeout
                
                let (data, response) = try await URLSession.shared.data(for: request)
                
                guard let httpResponse = response as? HTTPURLResponse else {
                    throw ScrapingError.pageInaccessible
                }
                
                if ScraperConfig.debugMode {
                    print("üì° [SCRAPER V2] HTTP \(httpResponse.statusCode)")
                }
                
                guard httpResponse.statusCode == 200 else {
                    throw ScrapingError.pageInaccessible
                }
                
                return String(decoding: data, as: UTF8.self)
                
            } catch {
                lastError = error
                if attempt < ScraperConfig.maxRetries {
                    try await Task.sleep(nanoseconds: 1_000_000_000) // 1 seconde
                }
            }
        }
        
        throw lastError ?? ScrapingError.reseauIndisponible
    }
    
    // MARK: - Extraction META Tags
    
    private func extraireMetaTags(html: String) -> [String: String] {
        var meta: [String: String] = [:]
        
        let metaPatterns: [(pattern: String, key: String)] = [
            (#"<meta\s+property="og:title"\s+content="([^"]+)"#, "og:title"),
            (#"<meta\s+property="og:description"\s+content="([^"]+)"#, "og:description"),
            (#"<meta\s+property="og:image"\s+content="([^"]+)"#, "og:image"),
            (#"<meta\s+name="description"\s+content="([^"]+)"#, "description"),
            (#"<meta\s+name="twitter:title"\s+content="([^"]+)"#, "twitter:title"),
            (#"<meta\s+name="twitter:description"\s+content="([^"]+)"#, "twitter:description"),
            (#"<meta\s+name="twitter:image"\s+content="([^"]+)"#, "twitter:image"),
            (#"<meta\s+itemprop="name"\s+content="([^"]+)"#, "itemprop:name"),
            (#"<meta\s+itemprop="description"\s+content="([^"]+)"#, "itemprop:description"),
            (#"<meta\s+itemprop="image"\s+content="([^"]+)"#, "itemprop:image"),
        ]
        
        for (pattern, key) in metaPatterns {
            if let range = html.range(of: pattern, options: .regularExpression) {
                let match = String(html[range])
                if let contentRange = match.range(of: #"content="([^"]+)"#, options: .regularExpression) {
                    var value = String(match[contentRange])
                    value = value.replacingOccurrences(of: #"content=""#, with: "")
                    value = value.replacingOccurrences(of: "\"", with: "")
                    meta[key] = decodeHTMLEntities(value)
                }
            }
        }
        
        if ScraperConfig.debugMode && !meta.isEmpty {
            print("üè∑Ô∏è [SCRAPER V2] META tags trouv√©s: \(meta.keys.joined(separator: ", "))")
        }
        
        return meta
    }
    
    // MARK: - Extraction JSON-LD
    
    private func extraireJSONLD(html: String) -> [String: Any] {
        let pattern = #"<script\s+type="application/ld\+json"[^>]*>(.*?)</script>"#
        
        guard let range = html.range(of: pattern, options: .regularExpression) else {
            return [:]
        }
        
        let scriptTag = String(html[range])
        
        // Extraire contenu entre balises
        guard let startRange = scriptTag.range(of: ">"),
              let endRange = scriptTag.range(of: "</script>") else {
            return [:]
        }
        
        let jsonString = String(scriptTag[startRange.upperBound..<endRange.lowerBound])
        
        guard let data = jsonString.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            return [:]
        }
        
        if ScraperConfig.debugMode {
            print("üì¶ [SCRAPER V2] JSON-LD trouv√© : @type = \(json["@type"] as? String ?? "inconnu")")
        }
        
        return json
    }
    
    // MARK: - Extraction NOM (15 patterns)
    
    private func extraireNom(html: String, meta: [String: String], jsonLD: [String: Any]) -> String? {
        // PRIORIT√â 1 : META tags
        if let nom = meta["og:title"] ?? meta["twitter:title"] ?? meta["itemprop:name"] {
            if ScraperConfig.debugMode {
                print("‚úÖ [NOM] META tag")
            }
            return nettoyerNom(nom)
        }
        
        // PRIORIT√â 2 : JSON-LD
        if let nom = jsonLD["name"] as? String {
            if ScraperConfig.debugMode {
                print("‚úÖ [NOM] JSON-LD")
            }
            return nettoyerNom(nom)
        }
        
        // PRIORIT√â 3 : HTML patterns
        let htmlPatterns = [
            #"<h1[^>]*class="[^"]*product[_-]?title[^"]*"[^>]*>(.*?)</h1>"#,
            #"<h1[^>]*class="[^"]*product[_-]?name[^"]*"[^>]*>(.*?)</h1>"#,
            #"<h1[^>]*id="product[_-]?title"[^>]*>(.*?)</h1>"#,
            #"<h1[^>]*itemprop="name"[^>]*>(.*?)</h1>"#,
            #"<div[^>]*class="[^"]*product[_-]?name[^"]*"[^>]*>(.*?)</div>"#,
            #"<title>(.*?)</title>"#,
        ]
        
        for pattern in htmlPatterns {
            if let range = html.range(of: pattern, options: .regularExpression) {
                let match = String(html[range])
                let cleaned = stripHTMLTags(match)
                if !cleaned.isEmpty {
                    if ScraperConfig.debugMode {
                        print("‚úÖ [NOM] HTML pattern")
                    }
                    return nettoyerNom(cleaned)
                }
            }
        }
        
        if ScraperConfig.debugMode {
            print("‚ùå [NOM] Aucun pattern trouv√©")
        }
        
        return nil
    }
    
    // MARK: - Extraction MARQUE (12 patterns)
    
    private func extraireMarque(html: String, meta: [String: String], jsonLD: [String: Any]) -> String? {
        // PRIORIT√â 1 : JSON-LD
        if let brand = jsonLD["brand"] as? [String: Any],
           let nom = brand["name"] as? String {
            if ScraperConfig.debugMode {
                print("‚úÖ [MARQUE] JSON-LD")
            }
            return nom
        }
        
        // PRIORIT√â 2 : HTML patterns
        let htmlPatterns = [
            #"<span[^>]*class="[^"]*brand[^"]*"[^>]*>(.*?)</span>"#,
            #"<div[^>]*class="[^"]*brand[_-]?name[^"]*"[^>]*>(.*?)</div>"#,
            #"<a[^>]*class="[^"]*brand[^"]*"[^>]*>(.*?)</a>"#,
            #"<meta[^>]+property="product:brand"[^>]+content="([^"]+)"#,
            #"<span[^>]*itemprop="brand"[^>]*>(.*?)</span>"#,
        ]
        
        for pattern in htmlPatterns {
            if let range = html.range(of: pattern, options: .regularExpression) {
                let match = String(html[range])
                let cleaned = stripHTMLTags(match).trimmingCharacters(in: .whitespacesAndNewlines)
                if !cleaned.isEmpty {
                    if ScraperConfig.debugMode {
                        print("‚úÖ [MARQUE] HTML pattern")
                    }
                    return cleaned
                }
            }
        }
        
        // PRIORIT√â 3 : D√©duction
        let marquesConnues = ["Rapala", "Nomad", "Flashmer", "Yo-Zuri", "Strike Pro",
                              "Savage Gear", "Shimano", "Daiwa", "Megabass", "Tackle House",
                              "Williamson", "Halco"]
        
        let textToSearch = "\(meta["og:title"] ?? "") \(html)"
        for marque in marquesConnues {
            if textToSearch.localizedCaseInsensitiveContains(marque) {
                if ScraperConfig.debugMode {
                    print("‚úÖ [MARQUE] D√©duite: \(marque)")
                }
                return marque
            }
        }
        
        if ScraperConfig.debugMode {
            print("‚ùå [MARQUE] Aucun pattern trouv√©")
        }
        
        return nil
    }
    
    // MARK: - Extraction DESCRIPTION LONGUE (20+ sources) ‚≠ê‚≠ê‚≠ê
    
    private func extraireDescriptionLongue(html: String, meta: [String: String], jsonLD: [String: Any]) -> String? {
        var allDescriptions: [String] = []
        
        if ScraperConfig.debugMode {
            print("üìù [DESCRIPTION] Recherche exhaustive...")
        }
        
        // NIVEAU 1 : META TAGS
        if let desc = meta["og:description"], !desc.isEmpty {
            allDescriptions.append(desc)
            if ScraperConfig.debugMode { print("   ‚úÖ og:description (\(desc.count) car)") }
        }
        
        if let desc = meta["description"], !desc.isEmpty, !allDescriptions.contains(desc) {
            allDescriptions.append(desc)
            if ScraperConfig.debugMode { print("   ‚úÖ meta description (\(desc.count) car)") }
        }
        
        if let desc = meta["twitter:description"], !desc.isEmpty, !allDescriptions.contains(desc) {
            allDescriptions.append(desc)
        }
        
        if let desc = meta["itemprop:description"], !desc.isEmpty, !allDescriptions.contains(desc) {
            allDescriptions.append(desc)
        }
        
        // NIVEAU 2 : JSON-LD
        if let desc = jsonLD["description"] as? String, !desc.isEmpty, !allDescriptions.contains(desc) {
            allDescriptions.append(desc)
            if ScraperConfig.debugMode { print("   ‚úÖ JSON-LD description (\(desc.count) car)") }
        }
        
        // NIVEAU 3 : SECTIONS HTML
        let descriptionPatterns: [(String, Int)] = [
            // Top Fishing - CAPTURER TOUT jusqu'√† photo_grandes
            (#"<div id="description"[^>]*>(.*?)<div id="photo_grandes""#, 88),
            
            // Flashmer - CAPTURER TOUT l'onglet
            (#"<div id="tab_description_tabbed"[^>]*>(.*?)</div>\s*</div>\s*<div class="panel"#, 87),
            
            // Flashmer - Section technique compl√®te
            (#"<div class="technical-description-container"[^>]*>(.*?)</div>\s*</div>"#, 86),
            
            // G√©n√©riques - Capturer conteneurs larges
            (#"<div[^>]*class="[^"]*product[_-]?description[^"]*"[^>]*>([\s\S]*?)</div>\s*</div>"#, 85),
            (#"<section[^>]*class="[^"]*description[^"]*"[^>]*>([\s\S]*?)</section>"#, 85),
            
            // IDs description - Version large
            (#"<div[^>]*id="description"[^>]*>([\s\S]*?)</div>\s*</div>"#, 80),
            
            // Fallback classiques
            (#"<div[^>]*class="[^"]*description[_-]?content[^"]*"[^>]*>(.*?)</div>"#, 75),
            (#"<div[^>]*id="product[_-]?description"[^>]*>(.*?)</div>"#, 75),
            (#"<div[^>]*itemprop="description"[^>]*>(.*?)</div>"#, 70),
        ]
        
        for (pattern, _) in descriptionPatterns {
            if let range = html.range(of: pattern, options: .regularExpression) {
                let match = String(html[range])
                let cleaned = nettoyerDescription(match)
                
                if !cleaned.isEmpty && cleaned.count > 20 {
                    let isDuplicate = allDescriptions.contains { existing in
                        existing == cleaned
                    }
                    
                    if !isDuplicate {
                        allDescriptions.append(cleaned)
                        if ScraperConfig.debugMode {
                            print("   ‚úÖ HTML section (\(cleaned.count) car)")
                        }
                    }
                }
            }
        }
        
        // NIVEAU 4 : TABLEAUX
        let tablePattern = #"<table[^>]*class="[^"]*specs?[^"]*"[^>]*>(.*?)</table>"#
        if let range = html.range(of: tablePattern, options: .regularExpression) {
            let match = String(html[range])
            let cleaned = nettoyerDescription(match)
            
            if cleaned.count > 20 {
                let isDuplicate = allDescriptions.contains { existing in
                    existing == cleaned
                }
                
                if !isDuplicate {
                    allDescriptions.append(cleaned)
                    if ScraperConfig.debugMode { print("   ‚úÖ Tableau specs (\(cleaned.count) car)") }
                }
            }
        }
        
        // FUSION FINALE
        guard !allDescriptions.isEmpty else {
            if ScraperConfig.debugMode { print("   ‚ùå Aucune description") }
            return nil
        }
        
        let finalDescription = allDescriptions.joined(separator: "\n\n")
        
        if ScraperConfig.debugMode {
            print("üéØ [DESCRIPTION] \(allDescriptions.count) sections : \(finalDescription.count) caract√®res")
        }
        
        return finalDescription
    }
    
    // MARK: - Extraction PHOTO
    
    private func extrairePhoto(html: String, meta: [String: String], jsonLD: [String: Any], baseURL: URL) -> String? {
        // PRIORIT√â 1 : META tags
        if let photo = meta["og:image"] ?? meta["twitter:image"] ?? meta["itemprop:image"] {
            if ScraperConfig.debugMode { print("‚úÖ [PHOTO] META tag") }
            return resoudreURL(photo, base: baseURL)
        }
        
        // PRIORIT√â 2 : JSON-LD
        if let photo = jsonLD["image"] as? String {
            if ScraperConfig.debugMode { print("‚úÖ [PHOTO] JSON-LD") }
            return resoudreURL(photo, base: baseURL)
        }
        
        // PRIORIT√â 3 : HTML patterns
        let photoPatterns = [
            #"<img[^>]*class="[^"]*product[_-]?image[^"]*"[^>]+src="([^"]+)"#,
            #"<img[^>]*id="product[_-]?image"[^>]+src="([^"]+)"#,
            #"<img[^>]*itemprop="image"[^>]+src="([^"]+)"#,
        ]
        
        for pattern in photoPatterns {
            if let range = html.range(of: pattern, options: .regularExpression) {
                let match = String(html[range])
                if let srcRange = match.range(of: #"src="([^"]+)"#, options: .regularExpression) {
                    var url = String(match[srcRange])
                    url = url.replacingOccurrences(of: #"src=""#, with: "")
                    url = url.replacingOccurrences(of: "\"", with: "")
                    if ScraperConfig.debugMode { print("‚úÖ [PHOTO] HTML pattern") }
                    return resoudreURL(url, base: baseURL)
                }
            }
        }
        
        if ScraperConfig.debugMode { print("‚ùå [PHOTO] Aucune trouv√©e") }
        return nil
    }
    
    // MARK: - Extraction param√®tres tra√Æne
    
    private func extraireParametresTraine(html: String, description: String?) -> (profMin: Double?, profMax: Double?, vitMin: Double?, vitMax: Double?) {
        let textToSearch = "\(html) \(description ?? "")"
        
        // Profondeur
        let profondeurPatterns = [
            #"(\d+(?:[.,]\d+)?)\s*[-√†a/]\s*(\d+(?:[.,]\d+)?)\s*(?:m|m√®tres?|meters?)"#,
            #"plonge.*?(\d+).*?(\d+)\s*(?:m|m√®tres)"#,
            #"depth.*?(\d+).*?(\d+)\s*(?:m|meters)"#,
            #"profondeur.*?(\d+).*?(\d+)"#,
        ]
        
        var profMin: Double?
        var profMax: Double?
        
        for pattern in profondeurPatterns {
            if let range = textToSearch.range(of: pattern, options: .regularExpression) {
                let match = String(textToSearch[range])
                let numbers = match.components(separatedBy: CharacterSet.decimalDigits.inverted)
                    .compactMap { Double($0.replacingOccurrences(of: ",", with: ".")) }
                if numbers.count >= 2 {
                    profMin = numbers[0]
                    profMax = numbers[1]
                    break
                }
            }
        }
        
        // Vitesse
        let vitessePatterns = [
            #"(\d+(?:[.,]\d+)?)\s*[-√†a/]\s*(\d+(?:[.,]\d+)?)\s*(?:kn|knots?|n≈ìuds?)"#,
            #"vitesse.*?(\d+).*?(\d+)\s*(?:kn|n≈ìuds)"#,
            #"speed.*?(\d+).*?(\d+)\s*(?:kn|knots)"#,
        ]
        
        var vitMin: Double?
        var vitMax: Double?
        
        for pattern in vitessePatterns {
            if let range = textToSearch.range(of: pattern, options: .regularExpression) {
                let match = String(textToSearch[range])
                let numbers = match.components(separatedBy: CharacterSet.decimalDigits.inverted)
                    .compactMap { Double($0.replacingOccurrences(of: ",", with: ".")) }
                if numbers.count >= 2 {
                    vitMin = numbers[0]
                    vitMax = numbers[1]
                    break
                }
            }
        }
        
        return (profMin, profMax, vitMin, vitMax)
    }
    
    // MARK: - D√©duction type leurre (ADAPT√â √Ä VOS ENUMS)
    
    private func deduireTypeLeurre(nom: String?, description: String?) -> TypeLeurre? {
        let text = "\(nom ?? "") \(description ?? "")".lowercased()
        
        // Ordre de priorit√© pour √©viter faux positifs
        
        // Jigs sp√©cifiques
        if text.contains("madai") || text.contains("mad'ai") || text.contains("tai rubber") {
            return .madai
        }
        if text.contains("inchiku") {
            return .inchiku
        }
        if text.contains("jig stick") || text.contains("jigstick") {
            if text.contains("coulant") || text.contains("sinking") {
                return .jigStickbaitCoulant
            }
            return .jigStickbait
        }
        if text.contains("vibe") || text.contains("lipless") || text.contains("vibration") {
            return .vibeLipless
        }
        if text.contains("jig vibrant") || text.contains("vibrating jig") {
            return .jigVibrant
        }
        if text.contains("metal jig") || text.contains("jig m√©tallique") || text.contains("jigging") {
            return .jigMetallique
        }
        
        // Stickbaits
        if text.contains("stickbait") || text.contains("stick bait") {
            if text.contains("coulant") || text.contains("sinking") {
                return .stickbaitCoulant
            }
            if text.contains("flottant") || text.contains("floating") {
                return .stickbaitFlottant
            }
            return .stickbait
        }
        
        // Poppers
        if text.contains("popper") || text.contains("popping") {
            return .popper
        }
        
        // Poissons nageurs
        if text.contains("minnow") || text.contains("poisson nageur") || text.contains("plugs") {
            if text.contains("vibrant") || text.contains("vibration") {
                return .poissonNageurVibrant
            }
            if text.contains("coulant") || text.contains("sinking") {
                return .poissonNageurCoulant
            }
            if text.contains("plongeant") || text.contains("diving") || text.contains("deep") {
                return .poissonNageurPlongeant
            }
            return .poissonNageur
        }
        
        // Autres types
        if text.contains("squid") || text.contains("calmar") || text.contains("pieuvre") {
            return .squid
        }
        if text.contains("skirt") || text.contains("jupe") || text.contains("octopus") {
            return .leurreAJupe
        }
        if text.contains("poisson volant") || text.contains("flying fish") {
            return .leurreDeTrainePoissonVolant
        }
        if text.contains("spoon") || text.contains("cuill√®re") || text.contains("cuiller") {
            return .cuiller
        }
        if text.contains("soft") || text.contains("souple") || text.contains("shad") {
            return .leurreSouple
        }
        
        return nil
    }
    
    // MARK: - D√©duction type p√™che (ADAPT√â √Ä VOS ENUMS)
    
    private func deduireTypePeche(typeLeurre: TypeLeurre) -> TypePeche? {
        switch typeLeurre {
        // Tra√Æne
        case .leurreAJupe, .popper, .leurreDeTrainePoissonVolant:
            return .traine
        case .poissonNageur, .poissonNageurPlongeant, .poissonNageurCoulant, .poissonNageurVibrant:
            return .traine
        case .cuiller:
            return .traine
            
        // Jigging
        case .jigMetallique, .jigVibrant, .madai, .inchiku:
            return .jigging
        case .jigStickbait, .jigStickbaitCoulant:
            return .jigging
            
        // Lancer
        case .stickbait, .stickbaitFlottant, .stickbaitCoulant:
            return .lancer
        case .vibeLipless:
            return .lancer
        case .leurreSouple, .squid:
            return .lancer
            
        default:
            return .traine // D√©faut
        }
    }
    
    private func typePecheCompatibles(pour typeLeurre: TypeLeurre) -> [TypePeche] {
        switch typeLeurre {
        // Polyvalents tra√Æne + lancer
        case .poissonNageur, .poissonNageurPlongeant, .cuiller:
            return [.traine, .lancer]
            
        // Polyvalents lancer + jigging
        case .leurreSouple, .squid:
            return [.lancer, .jigging]
            
        // Polyvalents jigging + tra√Æne
        case .jigMetallique:
            return [.jigging, .traine]
            
        default:
            return [] // Pas de compatibilit√© multiple
        }
    }
    
    // MARK: - Utilitaires nettoyage
    
    private func nettoyerDescription(_ raw: String) -> String {
        var text = raw
        text = stripHTMLTags(text)
        text = decodeHTMLEntities(text)
        text = text.replacingOccurrences(of: #"\s+"#, with: " ", options: .regularExpression)
        text = text.replacingOccurrences(of: #"\n{3,}"#, with: "\n\n", options: .regularExpression)
        return text.trimmingCharacters(in: .whitespacesAndNewlines)
    }
    
    private func nettoyerNom(_ raw: String) -> String {
        var text = stripHTMLTags(raw)
        text = decodeHTMLEntities(text)
        let parasites = [" - Achat", " | Boutique", " - En stock", " | Livraison", " | P√™cheur.com"]
        for parasite in parasites {
            text = text.replacingOccurrences(of: parasite, with: "")
        }
        return text.trimmingCharacters(in: .whitespacesAndNewlines)
    }
    
    private func stripHTMLTags(_ html: String) -> String {
        html.replacingOccurrences(of: #"<[^>]+>"#, with: "", options: .regularExpression)
    }
    
    private func decodeHTMLEntities(_ text: String) -> String {
        var result = text
        let entities = [
            "&nbsp;": " ", "&amp;": "&", "&lt;": "<", "&gt;": ">",
            "&quot;": "\"", "&#39;": "'", "&apos;": "'",
            "&eacute;": "√©", "&egrave;": "√®", "&ecirc;": "√™",
            "&agrave;": "√†", "&ccedil;": "√ß", "&ocirc;": "√¥"
        ]
        for (entity, char) in entities {
            result = result.replacingOccurrences(of: entity, with: char)
        }
        return result
    }
    
    private func resoudreURL(_ urlString: String, base: URL) -> String? {
        if urlString.hasPrefix("http") {
            return urlString
        }
        if urlString.hasPrefix("//") {
            return "https:\(urlString)"
        }
        if urlString.hasPrefix("/") {
            return base.scheme! + "://" + base.host! + urlString
        }
        return nil
    }
    
    // MARK: - T√©l√©chargement d'image
    
    /// T√©l√©charge une image depuis une URL et retourne un UIImage
    func telechargerImage(urlString: String) async throws -> UIImage {
        guard let url = URL(string: urlString) else {
            throw ScrapingError.urlInvalide
        }
        
        var request = URLRequest(url: url)
        request.setValue(ScraperConfig.userAgent, forHTTPHeaderField: "User-Agent")
        request.timeoutInterval = ScraperConfig.timeout
        
        let (data, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse,
              httpResponse.statusCode == 200 else {
            throw ScrapingError.pageInaccessible
        }
        
        guard let image = UIImage(data: data) else {
            throw ScrapingError.extractionEchouee
        }
        
        if ScraperConfig.debugMode {
            print("‚úÖ [IMAGE] T√©l√©charg√©e : \(data.count) octets")
        }
        
        return image
    }
}
